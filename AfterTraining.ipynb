{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "370513e4-c4db-43a2-9387-f876840c8b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement git (from versions: none)\n",
      "ERROR: No matching distribution found for git\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[sentencepiece] in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (4.29.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from transformers[sentencepiece]) (0.13.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from transformers[sentencepiece]) (22.0)\n",
      "Requirement already satisfied: requests in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from transformers[sentencepiece]) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from transformers[sentencepiece]) (1.23.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from transformers[sentencepiece]) (0.14.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from transformers[sentencepiece]) (3.9.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from transformers[sentencepiece]) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from transformers[sentencepiece]) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from transformers[sentencepiece]) (2023.5.5)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from transformers[sentencepiece]) (0.1.99)\n",
      "Requirement already satisfied: protobuf<=3.20.2 in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from transformers[sentencepiece]) (3.20.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[sentencepiece]) (2023.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[sentencepiece]) (4.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from tqdm>=4.27->transformers[sentencepiece]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from requests->transformers[sentencepiece]) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from requests->transformers[sentencepiece]) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from requests->transformers[sentencepiece]) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from requests->transformers[sentencepiece]) (2022.12.7)\n",
      "Collecting git+https://github.com/csebuetnlp/normalizer\n",
      "  Cloning https://github.com/csebuetnlp/normalizer to c:\\users\\razer\\appdata\\local\\temp\\pip-req-build-0teo1e20\n",
      "  Resolved https://github.com/csebuetnlp/normalizer to commit d80c3c484e1b80268f2b2dfaf7557fe65e34f321\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: regex in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from normalizer==0.0.1) (2023.5.5)\n",
      "Requirement already satisfied: emoji==1.4.2 in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from normalizer==0.0.1) (1.4.2)\n",
      "Requirement already satisfied: ftfy==6.0.3 in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from normalizer==0.0.1) (6.0.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from ftfy==6.0.3->normalizer==0.0.1) (0.2.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/csebuetnlp/normalizer 'C:\\Users\\RAZER\\AppData\\Local\\Temp\\pip-req-build-0teo1e20'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from nltk) (2023.5.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\razer\\anaconda3\\envs\\titanoboa\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install git\n",
    "!pip install transformers[sentencepiece]\n",
    "!pip install git+https://github.com/csebuetnlp/normalizer\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c660f09-f5de-4d71-8043-e12a9be23d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from normalizer import normalize # pip install git+https://github.com/csebuetnlp/normalizer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import torch\n",
    "\n",
    "# calling BanglaT5 model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"csebuetnlp/banglat5\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/banglat5\", use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85a00512-9dd9-4e67-a1c1-06e46f8194c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"C:/Users/RAZER/Documents/Sartaj/BQAG/model_weights_epoch_9.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9d30aaa-57ff-4295-9dc6-2e227f413fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def get_question_answer(context):\n",
    "      source_encoding=tokenizer(\n",
    "        context,\n",
    "        max_length=1024,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        add_special_tokens=True,\n",
    "        return_tensors=\"pt\").to(device)\n",
    "\n",
    "      #print(source_encoding)\n",
    "\n",
    "      generated_ids=model.generate(\n",
    "          input_ids=source_encoding[\"input_ids\"],\n",
    "          attention_mask=source_encoding[\"attention_mask\"],\n",
    "          num_beams = 1,\n",
    "          max_length=512,\n",
    "          repetition_penalty=2.5,\n",
    "          length_penalty=1.0,\n",
    "          early_stopping= True,\n",
    "          use_cache = True,\n",
    "      )\n",
    "\n",
    "    #print(generated_ids)\n",
    "\n",
    "      preds=[tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True) for gen_id in generated_ids]\n",
    "\n",
    "      #return \"\".join(preds), generated_ids\n",
    "      return \"\".join(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8797e84-9737-4440-ac3d-b84e57b110b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAZER\\anaconda3\\envs\\TitanoBoa\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# setup GPU/CPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# move model over to detected device\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "\n",
    "#calling the checkpoint and loading the parameters of the saved model for evaluation\n",
    "checkpoint = torch.load(model_name)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8547e01-aacf-466d-a9bd-59a57220f000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting glob2\n",
      "  Using cached glob2-0.7.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: glob2\n",
      "  Building wheel for glob2 (setup.py): started\n",
      "  Building wheel for glob2 (setup.py): finished with status 'done'\n",
      "  Created wheel for glob2: filename=glob2-0.7-py2.py3-none-any.whl size=9305 sha256=3ecb032ff46fb91b070dfc4d322e3c55b5e845321e21324c7ccbd5f5745c87e4\n",
      "  Stored in directory: c:\\users\\razer\\appdata\\local\\pip\\cache\\wheels\\c4\\50\\09\\61cb9fc21daef18f10394fbdc99ba8ca9bcbca50579d1f3c0f\n",
      "Successfully built glob2\n",
      "Installing collected packages: glob2\n",
      "Successfully installed glob2-0.7\n"
     ]
    }
   ],
   "source": [
    "!pip install glob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b30ff344-76a5-4d85-9691-a4edc313fe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas\n",
    "\n",
    "articles=[]\n",
    "\n",
    "for i in list(glob(\"C:/Users/RAZER/Documents/Sartaj/new_data/*\")):\n",
    "    df = pandas.read_csv(i)\n",
    "    df = df.dropna()\n",
    "    df = df.drop(['Unnamed: 0', 'class'], axis=1)\n",
    "    articles1 = list(df['article'])\n",
    "\n",
    "    for i in range(15000):\n",
    "        articles.append('c: ' + normalize(articles1[i]))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63b1d3c2-37c5-4776-b6f0-5cc4b46edce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2419c838-ac8f-4ece-92cf-6f0dcbc138f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def get_answer(context):\n",
    "    source_encoding=tokenizer(\n",
    "        context,\n",
    "        max_length=1024,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        add_special_tokens=True,\n",
    "        return_tensors=\"pt\").to(device)\n",
    "  \n",
    "  #print(source_encoding)\n",
    "    generated_ids=model.generate(\n",
    "        input_ids=source_encoding[\"input_ids\"],\n",
    "        attention_mask=source_encoding[\"attention_mask\"],\n",
    "        num_beams = 1,\n",
    "        max_length=256,\n",
    "        repetition_penalty=2.5,\n",
    "        length_penalty=1.0,\n",
    "        early_stopping= True,\n",
    "        use_cache = True)\n",
    "  \n",
    "  #print(generated_ids)\n",
    "\n",
    "    preds=[tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True) for gen_id in generated_ids]\n",
    "\n",
    "    return \"\".join(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a46b1632-6fa6-44c1-bb96-37f7447db67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of sample in Validation set:  15000\n"
     ]
    }
   ],
   "source": [
    "sample_total = len(articles)\n",
    "print('No of sample in Validation set: ', sample_total)\n",
    "qs = []\n",
    "ans=[]\n",
    "\n",
    "with torch.no_grad():\n",
    "    l = len(articles)\n",
    "    for i in range(l):\n",
    "        pred = get_answer(articles[i])\n",
    "        \n",
    "        x = pred.split(\"a:\")\n",
    "        if len(x)==1:\n",
    "            q=x[0].replace(\"q:\",\"\")\n",
    "            a=''\n",
    "        else:\n",
    "            q,a =x[0],x[1]\n",
    "            q=q.replace(\"q:\",\"\")\n",
    "        qs.append(q)\n",
    "        ans.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72be467c-9c60-4fa7-95a6-8602d8c0c65f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "202d141f-0e2a-40fa-b168-82f9e18a31a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "dic = {\n",
    "    \"Context\":articles,\n",
    "    \"Question\":qs,\n",
    "    \"Answer\":ans\n",
    "}\n",
    "df = pd.DataFrame(dic)\n",
    "df.to_csv(\"C:/Users/RAZER/Documents/Sartaj/new_data/New_data.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0651f31-e242-494e-b602-ab636490f6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c7922deb-4e0d-4a60-ace6-371dcc91c13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c:  শ্রাবন্তীর 'শিকারি'র পর এবার আরেক ছবি 'বাদ...</td>\n",
       "      <td>কবে ঢাকায় আসবেন জিৎ?</td>\n",
       "      <td>৩০ জুন</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c: টিভি অভিনেত্রী প্রত্যুষা ব্যানার্জিকে প্রায...</td>\n",
       "      <td>টিভি অভিনেত্রী প্রত্যুষা ব্যানার্জিকে কোথায় ...</td>\n",
       "      <td>ফাঁসিতে ঝুলন্ত অবস্থায়</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c: বাস্তবের দুই বোন ডেকোটা ফ্যানিং আর এল ফ্যান...</td>\n",
       "      <td>কে এই উপন্যাসে দুই বোনের ভূমিকায় অভিনয় করবেন?</td>\n",
       "      <td>ডেকোটা ফ্যানিং; এল ফ্যাং ক্রিস্টিন হ্যানা</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c: প্রবীণ চলচ্চিত্র অভিনেত্রী শবনম এখনও অভিনয়...</td>\n",
       "      <td>শবনমের অভিনীত সর্বশেষ সিনেমা কোনটি?</td>\n",
       "      <td>আম্মাজান</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c:  করোনাভাইরাস আতঙ্কে কাঁপছে সারা বিশ্ব। গত ড...</td>\n",
       "      <td>কবে চীনের উহান শহরে উৎপত্তির পর দুই মাসেই ১০৯...</td>\n",
       "      <td>গত ডিসেম্বরে</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c:  'সানি লিওন যেভাবে পুরুষদের আনন্দ দেয় প্রত...</td>\n",
       "      <td>রামগোপাল ভার্মা কি সানি লিওনকে আক্রমণ করেছিলেন?</td>\n",
       "      <td>হ্যাঁ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c: বিনোদন ডেস্ক : মোস্তফা সরয়ার ফারুকী পরিচাল...</td>\n",
       "      <td>কে ডুব-এর অনাপত্তিপত্র বাতিল করেন?</td>\n",
       "      <td>সেন্সর বোর্ড</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c: বিনোদন ডেস্ক : নাট্যনির্মাতা বিইউ শুভ নিজের...</td>\n",
       "      <td>বিইউ শুভ'র প্রথম চলচ্চিত্র কোনটি?</td>\n",
       "      <td>'গেম-টু'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c: সম্প্রতি অভিনেত্রী জ্যাকুলিন ফার্নান্ডেজ ও ...</td>\n",
       "      <td>কত সালে গানটি প্রকাশিত হয়?</td>\n",
       "      <td>১৯৭৬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>c:  অবশেষে মার্কিন পপতারকা প্রিন্স রজার্স নেলস...</td>\n",
       "      <td>প্রিন্স রজার্স নেলসনের মৃত্যু নিয়ে জল্পনা-কল...</td>\n",
       "      <td>অবশেষে</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Context  \\\n",
       "0  c:  শ্রাবন্তীর 'শিকারি'র পর এবার আরেক ছবি 'বাদ...   \n",
       "1  c: টিভি অভিনেত্রী প্রত্যুষা ব্যানার্জিকে প্রায...   \n",
       "2  c: বাস্তবের দুই বোন ডেকোটা ফ্যানিং আর এল ফ্যান...   \n",
       "3  c: প্রবীণ চলচ্চিত্র অভিনেত্রী শবনম এখনও অভিনয়...   \n",
       "4  c:  করোনাভাইরাস আতঙ্কে কাঁপছে সারা বিশ্ব। গত ড...   \n",
       "5  c:  'সানি লিওন যেভাবে পুরুষদের আনন্দ দেয় প্রত...   \n",
       "6  c: বিনোদন ডেস্ক : মোস্তফা সরয়ার ফারুকী পরিচাল...   \n",
       "7  c: বিনোদন ডেস্ক : নাট্যনির্মাতা বিইউ শুভ নিজের...   \n",
       "8  c: সম্প্রতি অভিনেত্রী জ্যাকুলিন ফার্নান্ডেজ ও ...   \n",
       "9  c:  অবশেষে মার্কিন পপতারকা প্রিন্স রজার্স নেলস...   \n",
       "\n",
       "                                            Question  \\\n",
       "0                             কবে ঢাকায় আসবেন জিৎ?    \n",
       "1   টিভি অভিনেত্রী প্রত্যুষা ব্যানার্জিকে কোথায় ...   \n",
       "2   কে এই উপন্যাসে দুই বোনের ভূমিকায় অভিনয় করবেন?    \n",
       "3               শবনমের অভিনীত সর্বশেষ সিনেমা কোনটি?    \n",
       "4   কবে চীনের উহান শহরে উৎপত্তির পর দুই মাসেই ১০৯...   \n",
       "5   রামগোপাল ভার্মা কি সানি লিওনকে আক্রমণ করেছিলেন?    \n",
       "6                কে ডুব-এর অনাপত্তিপত্র বাতিল করেন?    \n",
       "7                 বিইউ শুভ'র প্রথম চলচ্চিত্র কোনটি?    \n",
       "8                       কত সালে গানটি প্রকাশিত হয়?    \n",
       "9   প্রিন্স রজার্স নেলসনের মৃত্যু নিয়ে জল্পনা-কল...   \n",
       "\n",
       "                                       Answer  \n",
       "0                                      ৩০ জুন  \n",
       "1                     ফাঁসিতে ঝুলন্ত অবস্থায়  \n",
       "2   ডেকোটা ফ্যানিং; এল ফ্যাং ক্রিস্টিন হ্যানা  \n",
       "3                                    আম্মাজান  \n",
       "4                                গত ডিসেম্বরে  \n",
       "5                                       হ্যাঁ  \n",
       "6                                সেন্সর বোর্ড  \n",
       "7                                    'গেম-টু'  \n",
       "8                                        ১৯৭৬  \n",
       "9                                      অবশেষে  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/RAZER/Documents/Sartaj/new_data/New_data.csv\")\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6af7d1-34fa-485f-bb66-bb83363bd69c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
